{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d295a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jupyterthemes import get_themes\n",
    "# import jupyterthemes as jt\n",
    "# from jupyterthemes.stylefx import set_nb_theme\n",
    "# set_nb_theme('chesterish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3f92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d701dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('C:/Users/farha/Downloads/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(\"C:/Users/farha/Downloads/opencv/sources/data/haarcascades/haarcascade_eye.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dff41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1790994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if img is None:\n",
    "        return None\n",
    "    if gray is None:\n",
    "        return None\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d0a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moustache(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "            return None\n",
    "    else:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            y1 = int(y + (h/2))\n",
    "            h1 = int(h/2)\n",
    "            x1 = int(x + w/4)\n",
    "            w1 = int((3*w)/4)\n",
    "            roi_gray_moustache = gray[y1:y1+h1, x1:x1+w1].copy()\n",
    "            roi_color_moustache = img[y1:y1+h1, x1:x1+w1].copy()\n",
    "        return roi_color_moustache\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2256b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "facials = ['chevron moustache', 'walrus moustache styles', 'pencil moustache', 'handlebar moustache', 'horseshoe moustache']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cf25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "facials = [ 'toothbrush moustache']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6265275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This toothbrush moustache is Done!\n"
     ]
    }
   ],
   "source": [
    "for folder in facials:\n",
    "    dir_path = f\"C:/Users/farha/KAGGLE_DS_PROJECTS/Iconic Shades Classifier/train_data/{folder}\"\n",
    "    dir_path_cropped = dir_path + '_cropped2'\n",
    "    \n",
    "    files_in_folder = len([name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))])\n",
    "    \n",
    "    print(f\"This {folder} is Done!\")\n",
    "    if not os.path.exists(dir_path+'_cropped2'):\n",
    "        os.makedirs(dir_path_cropped)\n",
    "    os.chdir(dir_path_cropped)\n",
    "    for i in range(files_in_folder):\n",
    "        path = os.path.join(dir_path,str(f\"train({i+1})\")+'.jpg')\n",
    "        \n",
    "                    \n",
    "        roi_color = cropped_image_if_2_eyes(path)\n",
    "        if roi_color is not None:\n",
    "            \n",
    "            img = moustache(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            scaled_img = cv2.resize(img, (50,50))\n",
    "            filename = str(f\"train({i+1})\"+'.jpg')\n",
    "            cv2.imwrite(filename, scaled_img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Iconic Shades Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "081d6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "hulk = cv2.imread(r\"C:\\Users\\farha\\KAGGLE_DS_PROJECTS\\Iconic Shades Classifier\\train_data\\horseshoe moustache_cropped\\x.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "accf9baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_img = cv2.resize(hulk, (250,250))\n",
    "filename = str(f\"train(82)\"+'.jpg')\n",
    "cv2.imwrite(filename, scaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852ce10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
